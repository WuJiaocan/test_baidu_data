{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    从es里读取的content是html格式，需要解析成文本\n",
    "'''\n",
    "def sentencesMaker(html):\n",
    "    sentences = []\n",
    "    if not html or not html.strip():\n",
    "        return sentences\n",
    "    try:\n",
    "        from html.parser import unescape\n",
    "        html = unescape(html)\n",
    "\n",
    "        import justext\n",
    "        paragraphs = justext.justext(html, [])\n",
    "\n",
    "        cache_sentences = ''\n",
    "\n",
    "        for p in paragraphs:\n",
    "            sent = p.text.strip().replace('\\xa0', '').replace('\\u3000', '')\n",
    "            sent = sent.encode('gb2312', 'ignore').decode('gb2312').encode('gbk', 'ignore').decode('gbk')\n",
    "            if not sent:\n",
    "                continue\n",
    "\n",
    "            # 可能是含有名字，需要进一步处理\n",
    "            if len(cache_sentences) < 5:\n",
    "                cache_sentences += ' ' + sent\n",
    "            else:\n",
    "                sentences.append(cache_sentences.strip())\n",
    "                cache_sentences = sent\n",
    "\n",
    "        if not not cache_sentences:\n",
    "            sentences.append(cache_sentences.strip())\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "es = Elasticsearch('http://ip:port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "# def search_bl2(from_number, off_size):\n",
    "def search_bl2():\n",
    "    es_search_options = set_search_optional_bl2()\n",
    "    es_result = get_search_result(query=es_search_options, index=\"baidu_bl2\")\n",
    "    return es_result\n",
    "\n",
    "\n",
    "def get_search_result(query, index):\n",
    "    es_result = helpers.scan(\n",
    "        es,\n",
    "        query=query,\n",
    "        index=index,\n",
    "        doc_type='news',\n",
    "        scroll=\"10m\",\n",
    "        timeout='10m'\n",
    "    )\n",
    "    return es_result\n",
    "\n",
    "\n",
    "def set_search_optional_bl2(): \n",
    "    es_search_options = {\n",
    "   \"query\": {\n",
    "    \n",
    "    \"match_all\": {}\n",
    "  }\n",
    "  }\n",
    "    return es_search_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_results_bl2 = search_bl2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/lx/anaconda3/lib/python3.6/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.6680512428283691 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "\n",
    "jieba.load_userdict(\"./user_dict.txt\")\n",
    "\n",
    "import zhon.hanzi\n",
    "chi_char = zhon.hanzi.punctuation\n",
    "\n",
    "import string\n",
    "eng_char = string.punctuation\n",
    "\n",
    "with open(\"./stop_words.utf8\", \"r\", encoding=\"utf-8\") as stop_word:\n",
    "    stop_words = stop_word.readlines()\n",
    "    \n",
    "from sklearn.externals import joblib\n",
    "\n",
    "tfidf = joblib.load(\"./tfidf_vect_business.pkl\")\n",
    "svm = joblib.load(\"./svm_business.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160706\n"
     ]
    }
   ],
   "source": [
    "Y = []\n",
    "i = 0\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "for item in test_all_results_bl2:\n",
    "    i += 1\n",
    "    title_content = item[\"_source\"][\"title\"] + \"。\" + ''.join(sentencesMaker(item[\"_source\"][\"content\"]))\n",
    "    \n",
    "    token_text = [w.word for w in psg.cut(title_content) if w.flag.startswith('n') \n",
    "                  and w.word not in stop_words and w.word not in chi_char and w.word not in eng_char]\n",
    "\n",
    "    token_text = [reduce(lambda x,y:str(x)+ \" \" +str(y), token_text)]\n",
    "    \n",
    "    test_features = tfidf.transform(token_text)\n",
    "    \n",
    "    y_prediction = svm.predict(test_features)\n",
    "    \n",
    "    Y.extend(y_prediction.tolist())\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160706"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '1', '0', '1', '0', '1', '1', '1']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "百度正样本 48235 0.30014436299827013\n",
      "百度负样本 112471 0.6998556370017298\n"
     ]
    }
   ],
   "source": [
    "nlabel, plabel = 0, 0\n",
    "for i in Y:\n",
    "    if i == \"0\":\n",
    "        plabel += 1\n",
    "    else:\n",
    "        nlabel += 1\n",
    "print(\"百度正样本\", plabel, plabel/(plabel + nlabel))\n",
    "print(\"百度负样本\", nlabel, nlabel/(plabel + nlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
